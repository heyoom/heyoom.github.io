#!/bin/bash

# Obsidian â†’ Hugo ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ (published: trueë§Œ)

echo "ğŸ”„ Obsidian íŒŒì¼ ë™ê¸°í™” ì‹œì‘..."
echo ""

# content/posts, static/images í´ë” ì´ˆê¸°í™”
rm -rf content/posts
mkdir -p content/posts static/images

# vault ì „ì²´ì—ì„œ published: trueì¸ .md íŒŒì¼ ì°¾ê¸°
# (.obsidian, .trash ë“± ì‹œìŠ¤í…œ í´ë” ì œì™¸)
find -L obsidian-vault -name "*.md" \
  -not -path "*/\.obsidian/*" \
  -not -path "*/\.trash/*" \
  -not -path "*/\.smtcmp*/*" \
  -not -path "*/\.tmp*/*" \
  -not -path "*/\.space/*" \
  -not -path "*/\.assets/*" \
  2>/dev/null \
  | while read file; do
  # frontmatterì—ì„œ published: true ë˜ëŠ” published: "true" í™•ì¸
  if grep -qE "^published: (true|\"true\")" "$file"; then
    echo "âœ… Publishing: $file"

    # íŒŒì¼ëª… ì¶”ì¶œ
    filename=$(basename "$file")
    title=$(basename "$file" .md)

    # Wiki links ë³€í™˜, published í•„ë“œ ì œê±°, title/date ì¶”ê°€
    temp_file="/tmp/hugo_convert_$$.md"
    {
      # frontmatter ì‹œì‘
      echo "---"
      # titleì´ ì—†ìœ¼ë©´ ì¶”ê°€
      if ! grep -q "^title:" "$file"; then
        echo "title: \"$title\""
      fi
      # ê¸°ì¡´ frontmatter ë³µì‚¬ (published ì œì™¸)
      sed -n '/^---$/,/^---$/p' "$file" | sed '1d;$d' | grep -v "^published:"
      # date í•„ë“œê°€ ì—†ìœ¼ë©´ íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œí•´ì„œ ì¶”ê°€
      if ! grep -q "^date:" "$file"; then
        # íŒŒì¼ëª…ì´ YYYY-MM-DD í˜•ì‹ì¸ ê²½ìš° ë‚ ì§œ ì¶”ì¶œ
        if [[ "$title" =~ ^[0-9]{4}-[0-9]{2}-[0-9]{2}$ ]]; then
          echo "date: $title"
        fi
      fi
      echo "---"
      # ë³¸ë¬¸ ë³µì‚¬ (frontmatter ì´í›„)
      awk '/^---$/ {count++; next} count >= 2 {print}' "$file"
    } > "$temp_file"

    # Pythonìœ¼ë¡œ Wiki links ë³€í™˜ ë° image í•„ë“œ ì¶”ê°€
    python3 -c "
import re
import urllib.parse
import sys

with open('$temp_file', 'r', encoding='utf-8') as f:
    content = f.read()

# frontmatterì™€ ë³¸ë¬¸ ë¶„ë¦¬
match = re.match(r'(---\n)(.*?)(---\n)(.*)', content, re.DOTALL)
if not match:
    print(content, end='')
    sys.exit()

frontmatter_start = match.group(1)
frontmatter = match.group(2)
frontmatter_end = match.group(3)
body = match.group(4)

# ë³¸ë¬¸ì—ì„œ ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ì°¾ê¸°
first_image = None
image_match = re.search(r'!\[\[([^\]]+)\]\]', body)
if image_match:
    first_image = image_match.group(1)
    first_image_encoded = urllib.parse.quote(first_image)

# ë³¸ë¬¸ì—ì„œ description ì¶”ì¶œ (ì¼ë°˜ í…ìŠ¤íŠ¸ë§Œ, 160ì ì œí•œ)
description = None
text_lines = []
for line in body.split('\n'):
    line = line.strip()
    # ë¹ˆ ì¤„, í—¤ë”, ì´ë¯¸ì§€, ë¦¬ìŠ¤íŠ¸ ê±´ë„ˆë›°ê¸° (ì½”ë“œ ë¸”ë¡ ì²´í¬ ì œê±°)
    if line and not line.startswith('#') and not line.startswith('!') and not line.startswith('-') and not line.startswith('*') and not line.startswith('>'):
        # Markdown ë¬¸ë²• ì œê±°: **, __, [[]], []()
        clean_line = re.sub(r'\*\*([^*]+)\*\*', r'\1', line)  # **bold**
        clean_line = re.sub(r'__([^_]+)__', r'\1', clean_line)  # __bold__
        clean_line = re.sub(r'\*([^*]+)\*', r'\1', clean_line)  # *italic*
        clean_line = re.sub(r'_([^_]+)_', r'\1', clean_line)  # _italic_
        clean_line = re.sub(r'\[\[([^\]]+)\]\]', r'\1', clean_line)  # [[link]]
        clean_line = re.sub(r'\[([^\]]+)\]\([^\)]+\)', r'\1', clean_line)  # [text](url)
        # HTML íƒœê·¸ ì œê±°
        clean_line = re.sub(r'<[^>]+>', '', clean_line)
        clean_line = clean_line.strip()
        if clean_line:
            text_lines.append(clean_line)
            # 160ìê¹Œì§€ ì±„ìš°ê¸°
            if len(' '.join(text_lines)) >= 160:
                break

if text_lines:
    description = ' '.join(text_lines)[:160]

# ì´ë¯¸ì§€ ë§í¬ ë³€í™˜: ![[image.png]] -> ![image.png](/images/image.png)
def encode_image(match):
    img = match.group(1)
    encoded = urllib.parse.quote(img)
    return f'![{img}](/images/{encoded})'

# ë‚´ë¶€ ë§í¬ ë³€í™˜: [[title]] -> [title](/posts/title.md)
def encode_link(match):
    title = match.group(1)
    # íŒŒì¼ëª…ìœ¼ë¡œ ë³€í™˜ (Hugo slug ë°©ì‹)
    slug = title.lower().replace(' ', '-')
    return f'[{title}](/posts/{slug})'

body = re.sub(r'!\[\[([^\]]+)\]\]', encode_image, body)
body = re.sub(r'\[\[([^\]]+)\]\]', encode_link, body)

# frontmatterì— image í•„ë“œ ì¶”ê°€ (ì²« ë²ˆì§¸ ì´ë¯¸ì§€ê°€ ìˆê³ , image í•„ë“œê°€ ì—†ìœ¼ë©´)
if first_image and 'image:' not in frontmatter:
    frontmatter = frontmatter.rstrip() + f'\nimage: /images/{first_image_encoded}\n'

# frontmatterì— description í•„ë“œ ì¶”ê°€ (description í•„ë“œê°€ ì—†ìœ¼ë©´)
if description and 'description:' not in frontmatter:
    # ë”°ì˜´í‘œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
    description_escaped = description.replace('\"', '\\\"')
    frontmatter = frontmatter.rstrip() + f'\ndescription: \"{description_escaped}\"\n'

# ì¬ì¡°í•©
result = frontmatter_start + frontmatter + frontmatter_end + body
print(result, end='')
" > "content/posts/$filename"

    rm -f "$temp_file"

    # ì´ë¯¸ì§€ íŒŒì¼ ë³µì‚¬
    file_dir=$(dirname "$file")
    if [ -d "$file_dir/assets" ]; then
      find "$file_dir/assets" -type f \( -name "*.jpg" -o -name "*.jpeg" -o -name "*.png" -o -name "*.gif" -o -name "*.webp" \) -exec cp {} static/images/ \; 2>/dev/null
    fi
  fi
done

echo ""
echo "âœ¨ ë™ê¸°í™” ì™„ë£Œ!"
echo ""
echo "ğŸ“ ë°œí–‰ëœ ê¸€:"
ls -1 content/posts/ 2>/dev/null || echo "(ì—†ìŒ)"
echo ""
